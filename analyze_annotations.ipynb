{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             database_name table_name original_column_name  \\\n",
      "0  debit_card_specializing  yearmonth           CustomerID   \n",
      "1  debit_card_specializing  yearmonth                 Date   \n",
      "2  debit_card_specializing  yearmonth          Consumption   \n",
      "\n",
      "                                    GOLD Description  \\\n",
      "0              The unique identifier for a customer.   \n",
      "1             The year and month of the consumption.   \n",
      "2  The consumption value for a customer in a spec...   \n",
      "\n",
      "                                    LLM 1 Descripton Annotation LLM 1  \\\n",
      "0  Identifies a customer and is a foreign key tha...       4. Perfect   \n",
      "1  Stores the date of consumption for each customer.       4. Perfect   \n",
      "2  Records the consumption amount for a given cus...       4. Perfect   \n",
      "\n",
      "                                    LLM 2 Descripton   Annotation LLM 2  \\\n",
      "0  The CustomerID column is used to uniquely iden...  3. Almost perfect   \n",
      "1  The Date column in the yearmonth table represe...  3. Almost perfect   \n",
      "2  The Consumption column in the yearmonth table ...       1. Incorrect   \n",
      "\n",
      "                                    LLM 3 Descripton   Annotation LLM 3  \\\n",
      "0  The CustomerID column in the database serves a...  3. Almost perfect   \n",
      "1  The primary purpose of the Date column is to r...         4. Perfect   \n",
      "2  The primary purpose of the Consumption column ...       1. Incorrect   \n",
      "\n",
      "          Annotation  \n",
      "0  3. Almost perfect  \n",
      "1  3. Almost perfect  \n",
      "2       1. Incorrect  \n",
      "             database_name table_name original_column_name  \\\n",
      "0  debit_card_specializing  yearmonth           CustomerID   \n",
      "1  debit_card_specializing  yearmonth                 Date   \n",
      "2  debit_card_specializing  yearmonth          Consumption   \n",
      "\n",
      "                                    GOLD Description  \\\n",
      "0              The unique identifier for a customer.   \n",
      "1             The year and month of the consumption.   \n",
      "2  The consumption value for a customer in a spec...   \n",
      "\n",
      "                                    LLM 1 Descripton     Annotation LLM 1  \\\n",
      "0  Identifies a customer and is a foreign key tha...           4. Perfect   \n",
      "1  Stores the date of consumption for each customer.           4. Perfect   \n",
      "2  Records the consumption amount for a given cus...  2. Somewhat correct   \n",
      "\n",
      "                                    LLM 2 Descripton   Annotation LLM 2  \\\n",
      "0  The CustomerID column is used to uniquely iden...  3. Almost perfect   \n",
      "1  The Date column in the yearmonth table represe...  3. Almost perfect   \n",
      "2  The Consumption column in the yearmonth table ...       1. Incorrect   \n",
      "\n",
      "                                    LLM 3 Descripton   Annotation LLM 3  \\\n",
      "0  The CustomerID column in the database serves a...  3. Almost perfect   \n",
      "1  The primary purpose of the Date column is to r...         4. Perfect   \n",
      "2  The primary purpose of the Consumption column ...       1. Incorrect   \n",
      "\n",
      "          Annotation  \n",
      "0  3. Almost perfect  \n",
      "1  3. Almost perfect  \n",
      "2       1. Incorrect  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "annotator_names = ['Hjalmar', 'Sörme']\n",
    "annotations = []\n",
    "\n",
    "for name in annotator_names:\n",
    "    annotations.append(pd.read_excel('annotations/LLM Prediction Annotations(11).xlsx', sheet_name=name))\n",
    "\n",
    "for annotation in annotations:\n",
    "    annotation['Annotation'] = annotation['Annotation LLM 2'].fillna('No description')\n",
    "    print(annotation.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of annotations: 798\n",
      "\n",
      "The agreement percentage between the annotators:\n",
      "          Hjalmar     Sörme\n",
      "Hjalmar  1.000000  0.864662\n",
      "Sörme    0.864662  1.000000\n",
      "\n",
      "The Cohen's Kappa between the annotators:\n",
      "          Hjalmar     Sörme\n",
      "Hjalmar  1.000000  0.713345\n",
      "Sörme    0.713345  1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Agreememt percentage\n",
    "agreement = np.zeros((len(annotations), len(annotations)))\n",
    "cohen_kappa = np.zeros((len(annotations), len(annotations)))\n",
    "\n",
    "for anno_idx in range(len(annotations)):\n",
    "    for i in range(len(annotations[anno_idx])):\n",
    "        for anno_2_idx in range(len(annotations)):\n",
    "            agreement[anno_idx, anno_2_idx] = np.mean(annotations[anno_idx]['Annotation'] == annotations[anno_2_idx]['Annotation'])\n",
    "            cohen_kappa[anno_idx, anno_2_idx] = cohen_kappa_score(annotations[anno_idx]['Annotation'], annotations[anno_2_idx]['Annotation'])\n",
    "\n",
    "agreement_df = pd.DataFrame(agreement, columns=annotator_names, index=annotator_names)\n",
    "cohen_kappa_df = pd.DataFrame(cohen_kappa, columns=annotator_names, index=annotator_names)\n",
    "\n",
    "print(f\"The total number of annotations: {len(annotations[0])}\\n\")\n",
    "print(f\"The agreement percentage between the annotators:\\n{agreement_df}\\n\")\n",
    "print(f\"The Cohen's Kappa between the annotators:\\n{cohen_kappa_df}\") \n",
    "# Kappa value interpretation Landis & Koch (1977):\n",
    "# <0 No agreement\n",
    "# 0 — .20 Slight\n",
    "# .21 — .40 Fair\n",
    "# .41 — .60 Moderate\n",
    "# .61 — .80 Substantial\n",
    "# .81–1.0 Perfect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa: 0.10952614357439028\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load human annotations\n",
    "llm_judge_scores_path = \"output/judge/judge_mistral7b.csv\"\n",
    "human_annotations_path = \"annotations/LLM Prediction Annotations(13).xlsx\"\n",
    "human_annotations_df = pd.read_excel(human_annotations_path, sheet_name=\"Scores 123\")\n",
    "human_annotations_raw = human_annotations_df[\"Annotation 1 LLM 3\"]\n",
    "\n",
    "# Mapping of annotation values\n",
    "annotation_mapping = {\n",
    "    \"4. Perfect\": 4,\n",
    "    \"3. Almost perfect\": 3,\n",
    "    \"2. Somewhat correct\": 2,\n",
    "    \"1. Incorrect\": 1\n",
    "}\n",
    "\n",
    "\n",
    "human_annotations = human_annotations_raw.map(annotation_mapping)\n",
    "\n",
    "# Load LLM judge scores\n",
    "llm_judge_scores_path = \"output/judge/judge_qwen2-72B.csv\"\n",
    "llm_judge_scores_df = pd.read_csv(llm_judge_scores_path)\n",
    "llm_judge_scores = llm_judge_scores_df[\"judgement\"]\n",
    "\n",
    "# Create a DataFrame combining both annotations and judge scores\n",
    "combined_df = pd.DataFrame({\n",
    "    \"human_annotations\": human_annotations,\n",
    "    \"llm_judge_scores\": llm_judge_scores\n",
    "})\n",
    "\n",
    "# Drop rows with NaN values\n",
    "combined_df = combined_df.dropna()\n",
    "\n",
    "\n",
    "# Extract cleaned annotations and judge scores\n",
    "human_annotations_clean = combined_df[\"human_annotations\"].astype(int)\n",
    "llm_judge_scores_clean = combined_df[\"llm_judge_scores\"].astype(int)\n",
    "\n",
    "\n",
    "# Ensure both series are of the same length\n",
    "if len(human_annotations_clean) != len(llm_judge_scores_clean):\n",
    "    raise ValueError(\"The lengths of cleaned human annotations and LLM judge scores do not match\")\n",
    "\n",
    "# Calculate Cohen's kappa\n",
    "kappa = cohen_kappa_score(human_annotations_clean, llm_judge_scores_clean)\n",
    "\n",
    "print(f\"Cohen's kappa: {kappa}\")\n",
    "\n",
    "\n",
    "# # Apply the mapping to human annotations\n",
    "# human_annotations = human_annotations_raw.map(annotation_mapping)\n",
    "\n",
    "# # Load LLM judge scores\n",
    "\n",
    "# llm_judge_scores_df = pd.read_csv(llm_judge_scores_path)\n",
    "# llm_judge_scores = llm_judge_scores_df[\"judgement\"]\n",
    "\n",
    "# # Ensure both series are of the same length\n",
    "# if len(human_annotations) != len(llm_judge_scores):\n",
    "#     raise ValueError(\"The lengths of human annotations and LLM judge scores do not match\")\n",
    "\n",
    "# # Calculate Cohen's kappa\n",
    "# kappa = cohen_kappa_score(human_annotations, llm_judge_scores)\n",
    "\n",
    "# print(f\"Cohen's kappa: {kappa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa coefficient: 0.6128300606320377\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load the annotations\n",
    "niklas = pd.read_excel('annotations/Difficulty Annotation.xlsx', sheet_name='Niklas')\n",
    "ture = pd.read_excel('annotations/Difficulty Annotation.xlsx', sheet_name='Ture')\n",
    "\n",
    "\n",
    "# def merge_categories(annotation):\n",
    "#     if annotation in ['Medium', 'Hard']:\n",
    "#         return 'Medium/Hard'\n",
    "#     return annotation\n",
    "\n",
    "\n",
    "# oscar['Merged Annotation'] = oscar['Annotation'].apply(merge_categories)\n",
    "# ture['Merged Annotation'] = ture['Annotation'].apply(merge_categories)\n",
    "\n",
    "# Calculate the Cohen's kappa coefficient\n",
    "kappa = cohen_kappa_score(niklas['Annotation'], ture['Annotation'])\n",
    "\n",
    "print(f\"Cohen's kappa coefficient: {kappa}\")\n",
    "\n",
    "# kappa = cohen_kappa_score(oscar['Annotation'], ture['Annotation'])\n",
    "\n",
    "# print(f\"Merged Cohen's kappa coefficient: {kappa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.31213204951856943"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
